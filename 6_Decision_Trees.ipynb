{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# classifier we will use\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# model selection bits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Spam with Decision Trees\n",
    "\n",
    "In this assignment you will detect spam with decision trees. It's always important to investigate the data that you are using for any project. Since data is our gold mine, it's our oil that powers our models we need to have good quality data. Machine learning follows the \"garbage in, garbage out\" principle, if we feed in bad data for training, we will get a model that produces bad results.  For these reasons we want to answer the following questions.\n",
    "\n",
    "## 0.  Learn about the data\n",
    "\n",
    "1. Where did this data come from?\n",
    "2. Who made it?\n",
    "3. How were the features selected?\n",
    "4. Can you trust it?\n",
    "\n",
    "Go ahead and scan through the spambase_features.txt file and the spambase.txt file.  These two files provide information about the dataset, how it was curated and where it came from. Then try to answer the above questions.\n",
    "\n",
    "\n",
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we are going to hardcode the column names, because this just makes it a little easier to use pandas.\n",
    "\n",
    "names = ['word_freq_make:        ',\n",
    "'word_freq_address:     ',\n",
    "'word_freq_all:         ',\n",
    "'word_freq_3d:          ',\n",
    "'word_freq_our:         ',\n",
    "'word_freq_over:        ',\n",
    "'word_freq_remove:      ',\n",
    "'word_freq_internet:    ',\n",
    "'word_freq_order:       ',\n",
    "'word_freq_mail:        ',\n",
    "'word_freq_receive:     ',\n",
    "'word_freq_will:        ',\n",
    "'word_freq_people:      ',\n",
    "'word_freq_report:      ',\n",
    "'word_freq_addresses:   ',\n",
    "'word_freq_free:        ',\n",
    "'word_freq_business:    ',\n",
    "'word_freq_email:       ',\n",
    "'word_freq_you:         ',\n",
    "'word_freq_credit:      ',\n",
    "'word_freq_your:        ',\n",
    "'word_freq_font:        ',\n",
    "'word_freq_000:         ',\n",
    "'word_freq_money:       ',\n",
    "'word_freq_hp:          ',\n",
    "'word_freq_hpl:         ',\n",
    "'word_freq_george:      ',\n",
    "'word_freq_650:         ',\n",
    "'word_freq_lab:         ',\n",
    "'word_freq_labs:        ',\n",
    "'word_freq_telnet:      ',\n",
    "'word_freq_857:         ',\n",
    "'word_freq_data:        ',\n",
    "'word_freq_415:         ',\n",
    "'word_freq_85:          ',\n",
    "'word_freq_technology:  ',\n",
    "'word_freq_1999:        ',\n",
    "'word_freq_parts:       ',\n",
    "'word_freq_pm:          ',\n",
    "'word_freq_direct:      ',\n",
    "'word_freq_cs:          ',\n",
    "'word_freq_meeting:     ',\n",
    "'word_freq_original:    ',\n",
    "'word_freq_project:     ',\n",
    "'word_freq_re:          ',\n",
    "'word_freq_edu:         ',\n",
    "'word_freq_table:       ',\n",
    "'word_freq_conference:  ',\n",
    "'char_freq_;:           ',\n",
    "'char_freq_(:           ',\n",
    "'char_freq_[:           ',\n",
    "'char_freq_!:           ',\n",
    "'char_freq_$:           ',\n",
    "'char_freq_#:           ',\n",
    "'capital_run_length_average',\n",
    "'capital_run_length_longest',\n",
    "'capital_run_length_total: ',\n",
    "'label']\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the dataset here \n",
    "\n",
    "data = pd.read_csv('spambase/spambase.csv', names = names)\n",
    "X = data.drop('label', axis = 1)\n",
    "y = data.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the data if needed\n",
    "\n",
    "1. Are there any empty values?\n",
    "2. Do you need to transform the data?\n",
    "3. What is the distribution of the positive and negative classes?\n",
    "4. Split the data into training and testing sets\n",
    "\n",
    "Let me give a few hints.  When it comes to scaling the data, we normally just _should_, but in this case we are going to be working with decision trees and I think we learned that they have an interesting property!  \n",
    "\n",
    "We want to look at the distribution of positive (spam) and negative (ham) classes.  So basically we need to look at the count of the labels.  You can use the function `.value_counts()` on `y`.  Note that the function `value_counts` is specific to the Series class, it doesn't work on Dataframes.  Now it's not just enough to look at the raw numbers, I suggest you calculate statistics like \"what percentage of my data is ham? What percentage is spam?  This may help you decide if you should use the `stratify` keyword when splitting your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make:</th>\n",
       "      <th>word_freq_address:</th>\n",
       "      <th>word_freq_all:</th>\n",
       "      <th>word_freq_3d:</th>\n",
       "      <th>word_freq_our:</th>\n",
       "      <th>word_freq_over:</th>\n",
       "      <th>word_freq_remove:</th>\n",
       "      <th>word_freq_internet:</th>\n",
       "      <th>word_freq_order:</th>\n",
       "      <th>word_freq_mail:</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference:</th>\n",
       "      <th>char_freq_;:</th>\n",
       "      <th>char_freq_(:</th>\n",
       "      <th>char_freq_[:</th>\n",
       "      <th>char_freq_!:</th>\n",
       "      <th>char_freq_$:</th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make:          word_freq_address:       word_freq_all:           \\\n",
       "0                     0.00                     0.64                     0.64   \n",
       "1                     0.21                     0.28                     0.50   \n",
       "2                     0.06                     0.00                     0.71   \n",
       "3                     0.00                     0.00                     0.00   \n",
       "4                     0.00                     0.00                     0.00   \n",
       "\n",
       "   word_freq_3d:            word_freq_our:           word_freq_over:          \\\n",
       "0                      0.0                     0.32                     0.00   \n",
       "1                      0.0                     0.14                     0.28   \n",
       "2                      0.0                     1.23                     0.19   \n",
       "3                      0.0                     0.63                     0.00   \n",
       "4                      0.0                     0.63                     0.00   \n",
       "\n",
       "   word_freq_remove:        word_freq_internet:      word_freq_order:         \\\n",
       "0                     0.00                     0.00                     0.00   \n",
       "1                     0.21                     0.07                     0.00   \n",
       "2                     0.19                     0.12                     0.64   \n",
       "3                     0.31                     0.63                     0.31   \n",
       "4                     0.31                     0.63                     0.31   \n",
       "\n",
       "   word_freq_mail:          ...  word_freq_conference:    \\\n",
       "0                     0.00  ...                      0.0   \n",
       "1                     0.94  ...                      0.0   \n",
       "2                     0.25  ...                      0.0   \n",
       "3                     0.63  ...                      0.0   \n",
       "4                     0.63  ...                      0.0   \n",
       "\n",
       "   char_freq_;:             char_freq_(:             char_freq_[:             \\\n",
       "0                     0.00                    0.000                      0.0   \n",
       "1                     0.00                    0.132                      0.0   \n",
       "2                     0.01                    0.143                      0.0   \n",
       "3                     0.00                    0.137                      0.0   \n",
       "4                     0.00                    0.135                      0.0   \n",
       "\n",
       "   char_freq_!:             char_freq_$:             char_freq_#:             \\\n",
       "0                    0.778                    0.000                    0.000   \n",
       "1                    0.372                    0.180                    0.048   \n",
       "2                    0.276                    0.184                    0.010   \n",
       "3                    0.137                    0.000                    0.000   \n",
       "4                    0.135                    0.000                    0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total:   \n",
       "0                         278  \n",
       "1                        1028  \n",
       "2                        2259  \n",
       "3                         191  \n",
       "4                         191  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make:</th>\n",
       "      <th>word_freq_address:</th>\n",
       "      <th>word_freq_all:</th>\n",
       "      <th>word_freq_3d:</th>\n",
       "      <th>word_freq_our:</th>\n",
       "      <th>word_freq_over:</th>\n",
       "      <th>word_freq_remove:</th>\n",
       "      <th>word_freq_internet:</th>\n",
       "      <th>word_freq_order:</th>\n",
       "      <th>word_freq_mail:</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference:</th>\n",
       "      <th>char_freq_;:</th>\n",
       "      <th>char_freq_(:</th>\n",
       "      <th>char_freq_[:</th>\n",
       "      <th>char_freq_!:</th>\n",
       "      <th>char_freq_$:</th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285735</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make:          word_freq_address:       \\\n",
       "count              4601.000000              4601.000000   \n",
       "mean                  0.104553                 0.213015   \n",
       "std                   0.305358                 1.290575   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                   4.540000                14.280000   \n",
       "\n",
       "       word_freq_all:           word_freq_3d:            \\\n",
       "count              4601.000000              4601.000000   \n",
       "mean                  0.280656                 0.065425   \n",
       "std                   0.504143                 1.395151   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.420000                 0.000000   \n",
       "max                   5.100000                42.810000   \n",
       "\n",
       "       word_freq_our:           word_freq_over:          \\\n",
       "count              4601.000000              4601.000000   \n",
       "mean                  0.312223                 0.095901   \n",
       "std                   0.672513                 0.273824   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.380000                 0.000000   \n",
       "max                  10.000000                 5.880000   \n",
       "\n",
       "       word_freq_remove:        word_freq_internet:      \\\n",
       "count              4601.000000              4601.000000   \n",
       "mean                  0.114208                 0.105295   \n",
       "std                   0.391441                 0.401071   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                   7.270000                11.110000   \n",
       "\n",
       "       word_freq_order:         word_freq_mail:          ...  \\\n",
       "count              4601.000000              4601.000000  ...   \n",
       "mean                  0.090067                 0.239413  ...   \n",
       "std                   0.278616                 0.644755  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.160000  ...   \n",
       "max                   5.260000                18.180000  ...   \n",
       "\n",
       "       word_freq_conference:    char_freq_;:             \\\n",
       "count              4601.000000              4601.000000   \n",
       "mean                  0.031869                 0.038575   \n",
       "std                   0.285735                 0.243471   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                  10.000000                 4.385000   \n",
       "\n",
       "       char_freq_(:             char_freq_[:             \\\n",
       "count              4601.000000              4601.000000   \n",
       "mean                  0.139030                 0.016976   \n",
       "std                   0.270355                 0.109394   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.065000                 0.000000   \n",
       "75%                   0.188000                 0.000000   \n",
       "max                   9.752000                 4.081000   \n",
       "\n",
       "       char_freq_!:             char_freq_$:             \\\n",
       "count              4601.000000              4601.000000   \n",
       "mean                  0.269071                 0.075811   \n",
       "std                   0.815672                 0.245882   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.315000                 0.052000   \n",
       "max                  32.478000                 6.003000   \n",
       "\n",
       "       char_freq_#:             capital_run_length_average  \\\n",
       "count              4601.000000                 4601.000000   \n",
       "mean                  0.044238                    5.191515   \n",
       "std                   0.429342                   31.729449   \n",
       "min                   0.000000                    1.000000   \n",
       "25%                   0.000000                    1.588000   \n",
       "50%                   0.000000                    2.276000   \n",
       "75%                   0.000000                    3.706000   \n",
       "max                  19.829000                 1102.500000   \n",
       "\n",
       "       capital_run_length_longest  capital_run_length_total:   \n",
       "count                 4601.000000                 4601.000000  \n",
       "mean                    52.172789                  283.289285  \n",
       "std                    194.891310                  606.347851  \n",
       "min                      1.000000                    1.000000  \n",
       "25%                      6.000000                   35.000000  \n",
       "50%                     15.000000                   95.000000  \n",
       "75%                     43.000000                  266.000000  \n",
       "max                   9989.000000                15841.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2788\n",
       "1    1813\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split your data with 70% for training, this is somewhat random, but this is how I will do it in the \n",
    "## solution video so you will have similar results. Feel free to change this value and experiment if you like.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1951, 1269])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([837, 544])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a Decision Tree Classifier\n",
    "\n",
    "1. What metric should we use? The f1-score or accuracy?\n",
    "\n",
    "Let's start with a default model, we won't specify any settings on the decision tree model for the first training. The following will be a 3-step process\n",
    " * training\n",
    " * getting predictions\n",
    " * evaluating our predictions\n",
    " \n",
    "The question does arise, what should we check our predictions on? The obvious answer is that we should check the predictions on our testing set. That's the set of data that simulates our future unseen data. However in our quest to figure out if we are overfitting or not, it could be very useful to look at the performance of the training set.  Remember when we overfit our polynomials and they touched every point? But then we added data the performance would drop. Similarly if the perfomance of the training data is near perfect, but the testing data is much worse, that _gap_ indicates overfitting. So we will check both training and testing performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "clr = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get predictions from the model on the training data and the testing data\n",
    "clr.fit(X_train, y_train)\n",
    "predictions = clr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate the predictions\n",
    "## Note that the order of the arguments is **very** important for f1-score\n",
    "f_score = f1_score(y_test, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8767123287671232\n"
     ]
    }
   ],
   "source": [
    "print(f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Did we overfit? Either way, let's try out some of the decision tree parameters\n",
    "\n",
    "Go ahead and try out some different tree parameters. \n",
    "\n",
    "* `max_depth`\n",
    "* `min_samples_split`\n",
    "* `min_samples_leaf`\n",
    "\n",
    "All three of these parameters will control the complexity of the tree.  Before you try them out, let's take a quick quiz:\n",
    "\n",
    "* increasing `max_depth` will : **Increase** or **Decrease** overfitting?\n",
    "* increasing `min_samples_split` will: **Increase** or **Decrease** overfitting?\n",
    "* increasing `min_samples_leaf` will: **Increase** or **Decrease** overfitting?\n",
    "\n",
    "It's very important to know the answer to these questions - because other wise you can't tune the parameters correctly. If you aren't sure go back and check the quiz on this very topic.\n",
    "\n",
    "Go ahead and try at least 3 values for each parameter. Then if you try 3 values for each combination, you actually would try 9 total parameters. You can see where this is going -- `for` loops! At this point I encourage you to just try whatever method you want, you can ad-hoc try different values or you can get robust with for-loops. Whatever you are inspired to do. The main point is to try out some values and see what you find.  What helps improve our testing performance the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.8748824082784572\n",
      "2: 0.8834586466165414\n",
      "3: 0.8826815642458101\n",
      "4: 0.865979381443299\n",
      "5: 0.8705882352941177\n",
      "6: 0.8654404646660212\n",
      "7: 0.8495238095238096\n",
      "8: 0.7995824634655532\n",
      "9: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    clr = DecisionTreeClassifier(max_depth=10-i, min_samples_split=2, min_samples_leaf=2)\n",
    "    clr.fit(X_train, y_train)\n",
    "    predictions = clr.predict(X_test)\n",
    "    f_score = f1_score(y_test, predictions)\n",
    "    print(f\"{i}: {f_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: 0.8694798822374877\n",
      "9: 0.8694798822374877\n",
      "8: 0.8694798822374877\n",
      "7: 0.8705882352941177\n",
      "6: 0.8705882352941177\n",
      "5: 0.8694798822374877\n",
      "4: 0.8705882352941177\n",
      "3: 0.8705882352941177\n",
      "2: 0.8705882352941177\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    clr = DecisionTreeClassifier(max_depth=5, min_samples_split=11-i, min_samples_leaf=2)\n",
    "    clr.fit(X_train, y_train)\n",
    "    predictions = clr.predict(X_test)\n",
    "    f_score = f1_score(y_test, predictions)\n",
    "    print(f\"{11-i}: {f_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: 0.8641251221896383\n",
      "9: 0.8641251221896383\n",
      "8: 0.8618357487922705\n",
      "7: 0.8643410852713178\n",
      "6: 0.8635043562439496\n",
      "5: 0.8666017526777019\n",
      "4: 0.8694798822374877\n",
      "3: 0.8694798822374877\n",
      "2: 0.8694798822374877\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    clr = DecisionTreeClassifier(max_depth=5, min_samples_split=2, min_samples_leaf=11-i)\n",
    "    clr.fit(X_train, y_train)\n",
    "    predictions = clr.predict(X_test)\n",
    "    f_score = f1_score(y_test, predictions)\n",
    "    print(f\"{11-i}: {f_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max?: 0.8705882352941177\n"
     ]
    }
   ],
   "source": [
    "clr = DecisionTreeClassifier(max_depth=5, min_samples_split=2, min_samples_leaf=2)\n",
    "clr.fit(X_train, y_train)\n",
    "predictions = clr.predict(X_test)\n",
    "f_score = f1_score(y_test, predictions)\n",
    "print(f\"max?: {f_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ok, now let's do it systematically\n",
    "\n",
    "Let's do it with some for loops. This will lead us to having more data than we can \"look\" at, so naturally we will plot it.\n",
    "I've started the for loop for you, you need to fill in the inner part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7995824634655532, 0.8495238095238096, 0.8654404646660212, 0.8705882352941177, 0.8685927306616962, 0.881860465116279, 0.885981308411215, 0.8811973807296539, 0.8909774436090225, 0.8841121495327102, 0.8841121495327102, 0.8789571694599627, 0.8824626865671642, 0.8795518207282913, 0.8886827458256029, 0.883720930232558, 0.882079851439183, 0.8841519925857275, 0.8797061524334251, 0.8841911764705882, 0.8844036697247706, 0.8858447488584474, 0.8846153846153846, 0.8751139471285324, 0.8797814207650273, 0.8789808917197452, 0.8729582577132485, 0.877959927140255, 0.8755676657584014, 0.8836363636363637, 0.8760180995475113, 0.8751139471285324, 0.8769371011850501, 0.8708220415537489, 0.8701180744777475, 0.8680618744313011, 0.8722627737226277, 0.8705882352941176, 0.8754512635379061, 0.8768115942028986, 0.8714676390154967, 0.8675136116152451, 0.8747731397459164, 0.8731884057971014, 0.8808007279344858, 0.8745454545454545, 0.8731884057971014, 0.877959927140255]\n",
      " \n",
      "[0.9251207729468599, 0.8814229249011858, 0.9141104294478528, 0.9327731092436975, 0.8809073724007561, 0.8926553672316384, 0.9011406844106464, 0.8971428571428571, 0.9115384615384615, 0.8992395437262357, 0.8992395437262357, 0.8905660377358491, 0.8958333333333334, 0.8937381404174574, 0.897003745318352, 0.8945386064030132, 0.8911819887429644, 0.891588785046729, 0.8788990825688073, 0.8841911764705882, 0.8827838827838828, 0.8802177858439202, 0.8813868613138686, 0.8679927667269439, 0.871841155234657, 0.8702702702702703, 0.8620071684587813, 0.8700361010830325, 0.8653500897666068, 0.8741007194244604, 0.8627450980392157, 0.8679927667269439, 0.8698010849909584, 0.8561278863232682, 0.8599640933572711, 0.8594594594594595, 0.8659420289855072, 0.857397504456328, 0.8599290780141844, 0.8642857142857143, 0.864376130198915, 0.8566308243727598, 0.8637992831541219, 0.8607142857142858, 0.872072072072072, 0.8651079136690647, 0.8607142857142858, 0.8700361010830325]\n"
     ]
    }
   ],
   "source": [
    "train_results = []\n",
    "test_results = []\n",
    "test_results_prec = []\n",
    "for i in range(2,50): # feel free to change these, I just threw out a reasonable option here.\n",
    "    \n",
    "    dtc = DecisionTreeClassifier(max_depth=i)  #select a parameter to check\n",
    "    dtc.fit(X_train, y_train)                  # train the model\n",
    "    predictions = dtc.predict(X_test)           # get predictions for both training and test\n",
    "    test_results.append(f1_score(y_test, predictions))   # evaluate them and append them into the our lists.\n",
    "    test_results_prec.append(precision_score(y_test, predictions))\n",
    "    #train_results.append(dtc.score(X_train, y_train))\n",
    "\n",
    "print(test_results)\n",
    "print ( \" \")\n",
    "print (test_results_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's a lot of numbers!\n",
    "\n",
    "What do all those numbers tell us? Well we can pick out the best values using something like `np.max` and then we can relate it to the best parameter with the argument that correlates to that value (so depth 2 gave us .85 score etc).  But I think we'll find more interesting to plot these points.  I've provided the code for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f62bebc7be0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize = (10,6));\n",
    "ax.plot(test_results_prec, color = 'r', label = 'test prec')\n",
    "#ax.plot(train_results, color = 'r', label = 'train')\n",
    "ax.plot(test_results, color = 'b', label = 'test')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This graph is called a validation curve\n",
    "\n",
    "What we have done is plotted the performance of the training and testing data against a parameter that was varied. How do we read this graph?\n",
    "What information can you glean?\n",
    "When does our model start to overfit?  \n",
    "Based on what you see here, what do you think the best choice for the parameter you were checking is?  That is, looking at the graph, what value would you choose for a spam detection model that you were going to deploy? Don't forget the purpose of the model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth at 5 is a good candidate since precision is at its highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally... we ... made a mistake!\n",
    "Do you see what the giant mistake we did? Go ahead and let us know below.\n",
    "If you don't see the mistake... don't worry I'll explain in the next unit!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see a potential namespace conflict with the variable name f1_score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
